{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore predictor variables for floor height\n",
    "\n",
    "Explore correlation between exisiting floor height data and DEM and other building attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only points matched to footprint\n",
    "df_footprint = gpd.read_file('launceston_FFH_footprint_geometry.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match to DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "\n",
    "#DEM file\n",
    "#5m\n",
    "dempath = '/Users/madeleineseehaber/Library/CloudStorage/OneDrive-FrontierSI/127 Residential Dwelling Floor Height/4 Executing/GA_data_documentation/Launceston DEM/5m_DEM_70570.zip'#'/Users/Fangyuan/FrontierSI/Projects - Documents/Projects - Data Analytics/127 Residential Dwelling Floor Height/4 Executing/GA_data_documentation/Launceston DEM/5m_DEM_70570.zip'\n",
    "\n",
    "# Load the DEM raster from the ZIP file\n",
    "dem_raster = rioxarray.open_rasterio(f'zip://{dempath}!5m_DEM.tif')\n",
    "\n",
    "# Ensure that df_footprint is a GeoDataFrame with geometries\n",
    "# Initialize lists to store min and max values\n",
    "min_values = []\n",
    "max_values = []\n",
    "\n",
    "df_footprint = df_footprint.to_crs(dem_raster.rio.crs)\n",
    "# Iterate through each polygon in df_footprint\n",
    "for irow, row in df_footprint.iterrows():\n",
    "    # Mask the DEM raster with the polygon geometry\n",
    "    masked_dem = dem_raster.rio.clip(df_footprint.geometry.iloc[irow:irow+1], drop=True)\n",
    "\n",
    "    # Flatten the masked array and remove any NoData values\n",
    "    dem_values = masked_dem.values[masked_dem.values != masked_dem.rio.nodata]\n",
    "\n",
    "    # Append the min and max values\n",
    "    min_values.append(dem_values.min() if dem_values.size > 0 else None)\n",
    "    max_values.append(dem_values.max() if dem_values.size > 0 else None)\n",
    "\n",
    "# Add min and max values to df_footprint\n",
    "df_footprint['min_dem_5m'] = min_values\n",
    "df_footprint['max_dem_5m'] = max_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.enums import Resampling\n",
    "\n",
    "#DEM file\n",
    "#5m\n",
    "dempath = '/Users/madeleineseehaber/Library/CloudStorage/OneDrive-FrontierSI/127 Residential Dwelling Floor Height/4 Executing/GA_data_documentation/Launceston DEM/5m_DEM_70570.zip'#'/Users/Fangyuan/FrontierSI/Projects - Documents/Projects - Data Analytics/127 Residential Dwelling Floor Height/4 Executing/GA_data_documentation/Launceston DEM/5m_DEM_70570.zip'\n",
    "\n",
    "# Load the DEM raster from the ZIP file\n",
    "dem_raster_5m = rioxarray.open_rasterio(f'zip://{dempath}!5m_DEM.tif')\n",
    "\n",
    "# Calculate scaling factor to reach 1m resolution\n",
    "scale_factor = 5  # From 5m to 1m\n",
    "\n",
    "# Upscale to 1m resolution by interpolation\n",
    "dem_raster = dem_raster_5m.rio.reproject(\n",
    "    dem_raster_5m.rio.crs,\n",
    "    shape=(dem_raster_5m.shape[1] * scale_factor, dem_raster_5m.shape[2] * scale_factor),\n",
    "    resampling=Resampling.bilinear  # Use bilinear interpolation for smoother scaling\n",
    ")\n",
    "\n",
    "# Ensure that df_footprint is a GeoDataFrame with geometries\n",
    "# Initialize lists to store min and max values\n",
    "min_values = []\n",
    "max_values = []\n",
    "\n",
    "df_footprint = df_footprint.to_crs(dem_raster.rio.crs)\n",
    "# Iterate through each polygon in df_footprint\n",
    "for irow, row in df_footprint.iterrows():\n",
    "    # Mask the DEM raster with the polygon geometry\n",
    "    masked_dem = dem_raster.rio.clip(df_footprint.geometry.iloc[irow:irow+1], drop=True)\n",
    "\n",
    "    # Flatten the masked array and remove any NoData values\n",
    "    dem_values = masked_dem.values[masked_dem.values != masked_dem.rio.nodata]\n",
    "\n",
    "    # Append the min and max values\n",
    "    min_values.append(dem_values.min() if dem_values.size > 0 else None)\n",
    "    max_values.append(dem_values.max() if dem_values.size > 0 else None)\n",
    "\n",
    "# Add min and max values to df_footprint\n",
    "df_footprint['min_dem_1m_from_5m'] = min_values\n",
    "df_footprint['max_dem_1m_from_5m'] = max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define output path for the VRT\n",
    "vrt_path = '/Users/madeleineseehaber/Library/CloudStorage/OneDrive-FrontierSI/127 Residential Dwelling Floor Height/4 Executing/GA_data_documentation/Launceston DEM/1m_DEM.vrt'#'/Users/Fangyuan/FrontierSI/Projects - Documents/Projects - Data Analytics/127 Residential Dwelling Floor Height/4 Executing/GA_data_documentation/Launceston DEM/1m_DEM.vrt'\n",
    "\n",
    "# Load the DEM raster from the ZIP file\n",
    "dem_raster = rioxarray.open_rasterio(vrt_path)\n",
    "\n",
    "# Ensure that df_footprint is a GeoDataFrame with geometries\n",
    "# Initialize lists to store min and max values\n",
    "min_values = []\n",
    "max_values = []\n",
    "\n",
    "df_footprint = df_footprint.to_crs(dem_raster.rio.crs)\n",
    "# Iterate through each polygon in df_footprint\n",
    "for irow, row in df_footprint.iterrows():\n",
    "    # Mask the DEM raster with the polygon geometry\n",
    "    masked_dem = dem_raster.rio.clip(df_footprint.geometry.iloc[irow:irow+1], drop=True)\n",
    "\n",
    "    # Flatten the masked array and remove any NoData values\n",
    "    dem_values = masked_dem.values[masked_dem.values != masked_dem.rio.nodata]\n",
    "\n",
    "    # Append the min and max values\n",
    "    min_values.append(dem_values.min() if dem_values.size > 0 else None)\n",
    "    max_values.append(dem_values.max() if dem_values.size > 0 else None)\n",
    "\n",
    "# Add min and max values to df_footprint\n",
    "df_footprint['min_dem_1m'] = min_values\n",
    "df_footprint['max_dem_1m'] = max_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove LCC_FLOOR ==0\n",
    "df_footprint = df_footprint[df_footprint.LCC_FLOOR>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint.to_file('launceston_FFH_footprint_geometry_dem_range.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare 5m and 1m DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint['range_dem_5m'] = df_footprint['max_dem_5m'] - df_footprint['min_dem_5m']\n",
    "df_footprint['range_dem_1m'] = df_footprint['max_dem_1m'] - df_footprint['min_dem_1m']\n",
    "df_footprint['range_dem_1m_from_5m'] = df_footprint['max_dem_1m_from_5m'] - df_footprint['min_dem_1m_from_5m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint['range_dem_5m'].plot.hist(bins=50, label='range_dem_5m')\n",
    "df_footprint['range_dem_1m'].plot.hist(bins=50, label='range_dem_1m', alpha=0.7)\n",
    "df_footprint['range_dem_1m_from_5m'].plot.hist(bins=50, label='range_dem_1m_from_5m', alpha=0.7)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_footprint['min_dem_5m'], df_footprint['min_dem_1m'], alpha=0.6)\n",
    "plt.scatter(df_footprint['max_dem_5m'], df_footprint['max_dem_1m'], alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint['FFH_1m'] = df_footprint['LCC_FLOOR'] - df_footprint['min_dem_1m']\n",
    "df_footprint['FFH_5m'] = df_footprint['LCC_FLOOR'] - df_footprint['min_dem_5m']\n",
    "df_footprint['FFH_1m_from_5m'] = df_footprint['LCC_FLOOR'] - df_footprint['min_dem_1m_from_5m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_footprint[df_footprint['FFH_1m']>0]['range_dem_1m'], df_footprint[df_footprint['FFH_1m']>0]['range_dem_1m_from_5m'], alpha=0.6)\n",
    "plt.scatter(df_footprint[df_footprint['FFH_1m']>0]['range_dem_1m'], df_footprint[df_footprint['FFH_1m']>0]['range_dem_5m'], alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_footprint[df_footprint['FFH_1m']>0]['range_dem_1m'], df_footprint[df_footprint['FFH_1m']>0]['FFH_1m'], alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_footprint[df_footprint['FFH_1m']>0]['NEXIS_FLOO'], df_footprint[df_footprint['FFH_1m']>0]['FFH_1m'], alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint['min_dem_1m'].plot.hist(bins=50, label='min_dem')\n",
    "df_footprint['min_dem_5m'].plot.hist(bins=50, alpha=0.7, label='max_dem')\n",
    "df_footprint['DEM'].plot.hist(bins=50, alpha=0.7, label='DEM')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up categorical fields \n",
    "\n",
    "make all lower case; take first letter to combine y/yes, n/no etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cols = df_footprint.select_dtypes(exclude=[float, int]).columns[:-1]\n",
    "print(cate_cols)\n",
    "for col in cate_cols:\n",
    "    df_footprint[col] = df_footprint[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint['Survey_C_1'] = df_footprint['Survey_C_1'].str[0:1]\n",
    "df_footprint['Survey_Par'] = df_footprint['Survey_Par'].str[0:1]\n",
    "df_footprint['Survey_Gab'] = df_footprint['Survey_Gab'].str[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_footprint['LCC_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore regression model using different features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ffh_col = 'LCC_FLOOR' #'FFH_1m'\n",
    "df_r = df_footprint#[df_footprint[ffh_col]>0]\n",
    "#df_r = df_r[(df_r[ffh_col]>=0) & (df_r[ffh_col]<3)]\n",
    "\n",
    "cat_features = ['Survey_G_1','LCC_TYPE', 'Survey_C_1', 'NEXIS_ROOF', 'NEXIS_WALL', 'NEXIS_CONS']\n",
    "num_features = ['min_dem_1m', 'max_dem_1m', 'range_dem_1m', 'Survey_Grd', 'Survey_Chi', 'NEXIS_FOOT', 'NEXIS_FLOO', 'LOCAL_YEAR']\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_r[cat_features+num_features]\n",
    "y = df_r[ffh_col]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "encoder = OneHotEncoder()#sparse=False)\n",
    "X_encoded_categorical = encoder.fit_transform(X[cat_features]).toarray()\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_normalized_numeric = scaler.fit_transform(X[num_features])\n",
    "\n",
    "# Concatenate the encoded categorical features with the normalized numeric features\n",
    "X_encoded = np.hstack((X_encoded_categorical, X_normalized_numeric))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = r2_score(y_test, y_pred)\n",
    "print(f\"Explained Variance (R^2): {explained_variance:.4f}\")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_encoded, y, cv=5)  # 5-fold cross-validation\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print(f\"Cross-Validation Accuracy (R^2): {mean_cv_score:.4f}\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonal line\n",
    "plt.title(f'Actual vs Predicted {ffh_col}')\n",
    "plt.xlabel(f'Actual {ffh_col}')\n",
    "plt.ylabel(f'Predicted {ffh_col}')\n",
    "plt.grid(True)\n",
    "\n",
    "# Assuming 'model' is your trained RandomForestRegressor and X_encoded contains feature names\n",
    "importances = model.feature_importances_\n",
    "# Get the feature names (assuming you have them stored somewhere)\n",
    "feature_names = np.array(encoder.get_feature_names_out())\n",
    "all_feature_names = np.concatenate((feature_names, num_features))\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(all_feature_names[indices][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict LCC_FLOOR using DEM and Building attributes**\n",
    "\n",
    "As expected, floor elevation is mostly driven by DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ffh_col = 'FFH_1m'\n",
    "df_r = df_footprint[df_footprint[ffh_col]>0]\n",
    "#df_r = df_r[(df_r[ffh_col]>=0) & (df_r[ffh_col]<3)]\n",
    "\n",
    "cat_features = ['Survey_G_1', 'LCC_TYPE', 'Survey_C_1', 'NEXIS_ROOF', 'NEXIS_WALL', 'NEXIS_CONS']\n",
    "num_features = ['min_dem_1m', 'max_dem_1m', 'range_dem_1m', 'Survey_Grd', 'Survey_Chi', 'NEXIS_FOOT', 'NEXIS_FLOO', 'LOCAL_YEAR']\n",
    "\n",
    "cat_features = ['Survey_G_1', 'NEXIS_ROOF', 'NEXIS_WALL', 'NEXIS_YEAR'] #LCC_TYPE', 'Survey_C_1', 'Survey_Roo', 'Survey_Wal']\n",
    "num_features = ['min_dem_1m', 'range_dem_1m', 'LOCAL_YEAR' ]#, 'max_dem_1m', 'Survey_Grd', 'Survey_Chi', 'NEXIS_FOOT', 'NEXIS_FLOO']\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_r[cat_features+num_features]\n",
    "y = df_r[ffh_col]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "encoder = OneHotEncoder()#sparse=False)\n",
    "X_encoded_categorical = encoder.fit_transform(X[cat_features]).toarray()\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_normalized_numeric = scaler.fit_transform(X[num_features])\n",
    "\n",
    "# Concatenate the encoded categorical features with the normalized numeric features\n",
    "X_encoded = np.hstack((X_encoded_categorical, X_normalized_numeric))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = r2_score(y_test, y_pred)\n",
    "print(f\"Explained Variance (R^2): {explained_variance:.4f}\")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_encoded, y, cv=5)  # 5-fold cross-validation\n",
    "print(cv_scores)\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print(f\"Cross-Validation Accuracy (R^2): {mean_cv_score:.4f}\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonal line\n",
    "plt.title(f'Actual vs Predicted {ffh_col}')\n",
    "plt.xlabel(f'Actual {ffh_col}')\n",
    "plt.ylabel(f'Predicted {ffh_col}')\n",
    "plt.grid(True)\n",
    "\n",
    "# Assuming 'model' is your trained RandomForestRegressor and X_encoded contains feature names\n",
    "importances = model.feature_importances_\n",
    "# Get the feature names (assuming you have them stored somewhere)\n",
    "feature_names = np.array(encoder.get_feature_names_out())\n",
    "all_feature_names = np.concatenate((feature_names, num_features))\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(all_feature_names[indices][:10], importances[indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ffh_col = 'FFH_5m'\n",
    "df_r = df_footprint[df_footprint[ffh_col]>0]\n",
    "#df_r = df_r[(df_r[ffh_col]>=0) & (df_r[ffh_col]<3)]\n",
    "\n",
    "cat_features = ['Survey_G_1','LCC_TYPE', 'Survey_C_1', 'Survey_Roo', 'Survey_Wal']\n",
    "num_features = ['min_dem_1m', 'max_dem_1m', 'range_dem_1m', 'Survey_Grd', 'Survey_Chi', 'NEXIS_FOOT', 'NEXIS_FLOO', 'LOCAL_YEAR']\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_r[cat_features+num_features]\n",
    "y = df_r[ffh_col]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "encoder = OneHotEncoder()#sparse=False)\n",
    "X_encoded_categorical = encoder.fit_transform(X[cat_features]).toarray()\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_normalized_numeric = scaler.fit_transform(X[num_features])\n",
    "\n",
    "# Concatenate the encoded categorical features with the normalized numeric features\n",
    "X_encoded = np.hstack((X_encoded_categorical, X_normalized_numeric))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = r2_score(y_test, y_pred)\n",
    "print(f\"Explained Variance (R^2): {explained_variance:.4f}\")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_encoded, y, cv=5)  # 5-fold cross-validation\n",
    "print(cv_scores)\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print(f\"Cross-Validation Accuracy (R^2): {mean_cv_score:.4f}\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonal line\n",
    "plt.title(f'Actual vs Predicted {ffh_col}')\n",
    "plt.xlabel(f'Actual {ffh_col}')\n",
    "plt.ylabel(f'Predicted {ffh_col}')\n",
    "plt.grid(True)\n",
    "\n",
    "# Assuming 'model' is your trained RandomForestRegressor and X_encoded contains feature names\n",
    "importances = model.feature_importances_\n",
    "# Get the feature names (assuming you have them stored somewhere)\n",
    "feature_names = np.array(encoder.get_feature_names_out())\n",
    "all_feature_names = np.concatenate((feature_names, num_features))\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(all_feature_names[indices][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ffh_col = 'FFH_1m_from_5m'\n",
    "df_r = df_footprint[df_footprint[ffh_col]>0]\n",
    "#df_r = df_r[(df_r[ffh_col]>=0) & (df_r[ffh_col]<3)]\n",
    "\n",
    "cat_features = ['Survey_G_1','LCC_TYPE', 'Survey_C_1', 'Survey_Roo', 'Survey_Wal']\n",
    "num_features = ['min_dem_1m', 'max_dem_1m', 'range_dem_1m', 'Survey_Grd', 'Survey_Chi', 'NEXIS_FOOT', 'NEXIS_FLOO', 'LOCAL_YEAR']\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_r[cat_features+num_features]\n",
    "y = df_r[ffh_col]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "encoder = OneHotEncoder()#sparse=False)\n",
    "X_encoded_categorical = encoder.fit_transform(X[cat_features]).toarray()\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_normalized_numeric = scaler.fit_transform(X[num_features])\n",
    "\n",
    "# Concatenate the encoded categorical features with the normalized numeric features\n",
    "X_encoded = np.hstack((X_encoded_categorical, X_normalized_numeric))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = r2_score(y_test, y_pred)\n",
    "print(f\"Explained Variance (R^2): {explained_variance:.4f}\")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_encoded, y, cv=5)  # 5-fold cross-validation\n",
    "print(cv_scores)\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "print(f\"Cross-Validation Accuracy (R^2): {mean_cv_score:.4f}\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonal line\n",
    "plt.title(f'Actual vs Predicted {ffh_col}')\n",
    "plt.xlabel(f'Actual {ffh_col}')\n",
    "plt.ylabel(f'Predicted {ffh_col}')\n",
    "plt.grid(True)\n",
    "\n",
    "# Assuming 'model' is your trained RandomForestRegressor and X_encoded contains feature names\n",
    "importances = model.feature_importances_\n",
    "# Get the feature names (assuming you have them stored somewhere)\n",
    "feature_names = np.array(encoder.get_feature_names_out())\n",
    "all_feature_names = np.concatenate((feature_names, num_features))\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(all_feature_names[indices][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict FFH using DEM, DEM range and building attributes**\n",
    "\n",
    "DEM range is the most important feature; 1m DEM works better than 5m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check negative FFH\n",
    "\n",
    "Negative FFH tend to occur on steep slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_footprint[df_footprint.FFH<0][['LID', 'ADDRESS', 'Survey_G_1', 'DEM', 'min_dem_1m', 'max_dem_1m', 'LCC_FLOOR', 'FFH', 'FFH_1m']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_footprint[df_footprint['FFH_1m']>0]['range_dem_1m'], df_footprint[df_footprint['FFH_1m']>0]['FFH_1m'], alpha=0.6, label='FFH>0')\n",
    "plt.scatter(df_footprint[df_footprint['FFH_1m']<=0]['range_dem_1m'], df_footprint[df_footprint['FFH_1m']<=0]['FFH_1m'], alpha=0.6, label='FFH<0')\n",
    "plt.xlabel('DEM Range within footprint')\n",
    "plt.ylabel('FFH_1m')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floorheight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
