{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook queries .las file tiles using tile index file, then merges and clips the point cloud to building footprint extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import  mapping\n",
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import pdal\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_footprint_path = r'/home/ubuntu/lavender_floor_height/GA-floor-height/data/wagga_ffh.gpkg' # building footprints\n",
    "tile_index_file=r\"01_WaggaWagga/03_Ancillary/01_TileIndex/rev1/48068_Wagga_Wagga_TileSet.shp\"\n",
    "building_points_file=r'/home/ubuntu/lavender_floor_height/output/Final_Wagga_training_samples_pano_metadata.geojson'\n",
    "output_directory='/mnt/floorheightvolume/lidar_Wagga'\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AWS buket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfa_token = '896573' # replace with latest token\n",
    "cmd = (f'aws sts get-session-token --serial-number arn:aws:iam::693903849513:mfa/Lavender_AWS_MFA  --token-code {mfa_token}').split()\n",
    "result = subprocess.run(cmd, capture_output=True)\n",
    "bucket_name = 'frontiersi-p127-floor-height-woolpert'\n",
    "s3_prefix='01_WaggaWagga/02_MLSPointCloud/rev1/'\n",
    "\n",
    "# Check if the command was successful\n",
    "if result.returncode == 0:\n",
    "    # Parse JSON output into a dictionary\n",
    "    data = json.loads(result.stdout)\n",
    "    #print(data)  # Print or process the dictionary\n",
    "else:\n",
    "    print(\"Error:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=data['Credentials']['AccessKeyId'],\n",
    "    aws_secret_access_key=data['Credentials']['SecretAccessKey'],\n",
    "    aws_session_token=data['Credentials']['SessionToken']\n",
    ")\n",
    "# Initialize an S3 client\n",
    "s3 = session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download tile index files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all objects in the bucket with the shapefile base name\n",
    "response = s3.list_objects_v2(Bucket=bucket_name,Prefix=tile_index_file.split('.')[-2])\n",
    "for obj in response['Contents']:\n",
    "    key = obj['Key']\n",
    "    tile_index_file_downloaded=os.path.join(output_directory, os.path.basename(key))\n",
    "    if os.path.exists(tile_index_file_downloaded):\n",
    "        print('tile index file exists')\n",
    "    else:\n",
    "        # Download LAS file from S3\n",
    "        s3.download_file(bucket_name, key, tile_index_file_downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load downloaded tile index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_index_file_local=os.path.join(output_directory, os.path.basename(tile_index_file))\n",
    "gdf_tile_bbox=gpd.read_file(tile_index_file_local)\n",
    "gdf_tile_bbox.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load building footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_footprint=gpd.read_file(building_footprint_path).to_crs(gdf_tile_bbox.crs)\n",
    "gdf_building_footprint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_footprint.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_building_footprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load building points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_points=gpd.read_file(building_points_file).to_crs(gdf_tile_bbox.crs)\n",
    "gdf_building_points=gdf_building_points[gdf_building_points[\"USAGE\"]==\"Residential\"].reset_index(drop=True)\n",
    "gdf_building_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_points.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gdf_building_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_points=gdf_building_points.rename(columns={'index_right': 'pano_index_right'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify overlapping footprints and tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_gdf_footprint = gpd.sjoin_nearest(gdf_building_footprint,gdf_building_points,how='inner',max_distance=0.5,distance_col='bd_distance').reset_index(drop=True)\n",
    "nearby_gdf_footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=nearby_gdf_footprint.explore(color='blue',name='building footprint')\n",
    "gdf_building_points.explore(m=m,color='red',name='building points')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer building footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_distance = 2  # Adjust buffer distance based on CRS (e.g., meters or degrees)\n",
    "nearby_gdf_footprint_buffered=nearby_gdf_footprint.copy()\n",
    "nearby_gdf_footprint_buffered['geometry'] = nearby_gdf_footprint_buffered.buffer(buffer_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the workflow for a single building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find overlapping tile(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_polygon = nearby_gdf_footprint_buffered.geometry.iloc[0]\n",
    "# Find overlapping tiles\n",
    "overlapping_tiles = gdf_tile_bbox[gdf_tile_bbox.geometry.intersects(building_polygon)]\n",
    "overlapping_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=overlapping_tiles.explore(color='blue',name='overlapping lidar tiles')\n",
    "nearby_gdf_footprint.explore(m=m1,color='red',name='building footprints')\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all overlapping tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and process each overlapping tile\n",
    "output_directory_original='/mnt/floorheightvolume/lidar_Wagga/original'\n",
    "os.makedirs(output_directory_original, exist_ok=True)\n",
    "local_las_files=[]\n",
    "\n",
    "for _, tile in overlapping_tiles.iterrows():\n",
    "    las_file_key=os.path.join(s3_prefix,tile[\"FileName\"])\n",
    "    # tile_name = os.path.basename(las_file_key)\n",
    "    local_las_path = os.path.join(output_directory_original, tile[\"FileName\"])\n",
    "    local_las_files.append(local_las_path)\n",
    "    \n",
    "    if os.path.exists(local_las_path):\n",
    "        print('tile already downloaded')\n",
    "    else:\n",
    "        # Download LAS file from S3\n",
    "        s3.download_file(bucket_name, las_file_key, local_las_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and clip to footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get polygon CRS\n",
    "polygon_crs = nearby_gdf_footprint_buffered.crs.to_string() if nearby_gdf_footprint_buffered.crs else None\n",
    "las_crs='EPSG:7855' # needs to update based on study area or extracted from file name\n",
    "polygon_crs==las_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_clipped='/mnt/floorheightvolume/lidar_Wagga/clipped'\n",
    "os.makedirs(output_directory_clipped, exist_ok=True)\n",
    "outfile_basename='gnaf_'+nearby_gdf_footprint_buffered.iloc[0].gnaf_id+'_UFI_'+str(nearby_gdf_footprint_buffered.iloc[0].UFI)+'.las'\n",
    "out_las_clipped=os.path.join(output_directory_clipped,outfile_basename)\n",
    "\n",
    "# Create the base pipeline with readers\n",
    "pipeline_steps = []\n",
    "if len(local_las_files)>1:\n",
    "    pipeline_steps.extend(local_las_files)\n",
    "else:\n",
    "    pipeline_steps.append(local_las_files[0])\n",
    "\n",
    "# Add cropping filter\n",
    "bounds_formatted=f\"[{building_polygon.bounds[0]},{building_polygon.bounds[2]},{building_polygon.bounds[1]},{building_polygon.bounds[3]}]\"\n",
    "pipeline_steps.append({\n",
    "    \"type\": \"filters.crop\",\n",
    "    \"bounds\": bounds_formatted, # Pre-filter with bounds for efficiency\n",
    "    \"polygon\": mapping(building_polygon)\n",
    "})\n",
    "# Add writer\n",
    "pipeline_steps.append({\n",
    "    \"type\": \"writers.las\",\n",
    "    \"filename\": out_las_clipped,\n",
    "    \"extra_dims\": \"all\"  # Preserve all dimensions\n",
    "})\n",
    "# Create the pipeline\n",
    "pipeline_json = {\"pipeline\": pipeline_steps}\n",
    "try:\n",
    "    # Execute the pipeline\n",
    "    pipeline = pdal.Pipeline(json.dumps(pipeline_json))\n",
    "    pipeline.execute()\n",
    "except Exception as e:\n",
    "    print(f\"Pipeline failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
