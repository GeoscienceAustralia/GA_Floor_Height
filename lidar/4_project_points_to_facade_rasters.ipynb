{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates projection of point cloud at the viewpoint of nearby panorma as rasters, and export clipped rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "# from pyproj import Transformer\n",
    "# from scipy.spatial.transform import Rotation as R\n",
    "from lidar.point_cloud_processings import project_las_to_equirectangular, fill_small_nans, resize_preserve_nans\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import pyproj\n",
    "import os\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_points_file=r'/home/ubuntu/lavender_floor_height/output/Final_Wagga_training_samples_pano_metadata_clipping.geojson'\n",
    "las_files_folder = r\"/mnt/floorheightvolume/lidar_Wagga/clipped/\"\n",
    "out_folder=r\"/mnt/floorheightvolume/lidar_Wagga/clipped_projected/\"\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load building points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_points=gpd.read_file(building_points_file)\n",
    "gdf_building_points=gdf_building_points[gdf_building_points[\"USAGE\"]==\"Residential\"].reset_index(drop=True)\n",
    "gdf_building_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test workflow with one building example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify corresponding las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building_ufi=1271\n",
    "# gdf_building_points[gdf_building_points['UFI']==building_ufi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=90\n",
    "building_ufi=gdf_building_points.iloc[i]['UFI']\n",
    "house_loc_left, house_loc_right = int(gdf_building_points.iloc[i]['house_loc_left']), int(gdf_building_points.iloc[i]['house_loc_right'])\n",
    "las_file_path=glob.glob(las_files_folder+'*'+'_UFI_'+str(building_ufi)+'.las')[0]\n",
    "las_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject trajectory coordinates to match lidar points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = pyproj.Transformer.from_crs(\"EPSG:7844\",  # GDA2020 geographic (lat/lon)\n",
    "                                          \"EPSG:7855\",      # MGA Zone 55 (EPSG:7855)\n",
    "                                          always_xy=True)\n",
    "lat, lon, elev = [gdf_building_points.iloc[i]['LATITUDE'],gdf_building_points.iloc[i]['LONGITUDE'],gdf_building_points.iloc[i]['LTP_z_m']] # lidar data is in AHD\n",
    "x_proj, y_proj = transformer.transform(lon, lat)  # lon, lat order\n",
    "camera_pos_proj = [x_proj, y_proj, elev]\n",
    "camera_angles=[gdf_building_points.iloc[i]['Heading_deg'], gdf_building_points.iloc[i]['Pitch_deg'], (-1)*gdf_building_points.iloc[i]['Roll_deg']] # TODO: figure out why reversed sign works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_points.iloc[i]['Pitch_deg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_points.iloc[i]['LTP_z_m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densify points (optional depending on performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_densified_path=las_file_path.split('.')[0]+'_densified.las'\n",
    "# pipeline_json = {\n",
    "#     \"pipeline\": [\n",
    "#         las_file_path,\n",
    "#         {\n",
    "#             \"type\": \"filters.poisson\",\n",
    "#             \"depth\": 10, # Start with a mid-range depth (this controls resolution)\n",
    "#         },\n",
    "#         out_densified_path\n",
    "#     ]\n",
    "# }\n",
    "# pipeline = pdal.Pipeline(json.dumps(pipeline_json))\n",
    "# pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project the point cloud as rasters\n",
    "* Note: using the same width/height ratio as panoramas\n",
    "* reduced resolution to improve sampling of surface points compared to background points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_crop=0.25\n",
    "lower_crop=0.6 # consistent with panorama clipping\n",
    "width_panorama=11000\n",
    "height_panorama=5500  # panoramas parameters\n",
    "downscale_factor=4 # scale factor between panorama and projected lidar rasters\n",
    "width=int(width_panorama/downscale_factor)\n",
    "height=int(height_panorama/downscale_factor)\n",
    "rgb, z, depth, classification, intensity = project_las_to_equirectangular(input_las=las_file_path, camera_pos=camera_pos_proj,\n",
    "                                                               camera_angles=camera_angles, width=width, height=height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate gaps on elevation and intensity rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill small holes\n",
    "# z_arr_clipped_filled = fill_small_nans(z_arr_clipped, max_hole_size=5)\n",
    "z_arr_filled = fill_small_nans(z, max_hole_size=10, nodata_value=9999)\n",
    "intensity_filled = fill_small_nans(intensity, max_hole_size=10, nodata_value=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample to the same resolution as panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resize while preserving remaining NaNs\n",
    "# new_width = z_arr_clipped_filled.shape[0]*downscale_factor\n",
    "# new_height = z_arr_clipped_filled.shape[1]*downscale_factor\n",
    "# z_arr_filled_resampled=resize_preserve_nans(z_arr_clipped_filled,new_width,new_height)\n",
    "\n",
    "z_filled_resampled=resize_preserve_nans(z_arr_filled,height_panorama, width_panorama, nodata_value=9999)\n",
    "intensity_filled_resampled=resize_preserve_nans(intensity_filled, height_panorama, width_panorama, nodata_value=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip projected rasters to the same region as panoramas\n",
    "* only elevation and intensity rasters were upsampled for use in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_processed=z_filled_resampled[int(round(upper_crop*height_panorama)):int(round(lower_crop*height_panorama)),\n",
    "                               house_loc_left:house_loc_right]\n",
    "intensity_processed=intensity_filled_resampled[int(round(upper_crop*height_panorama)):int(round(lower_crop*height_panorama)),\n",
    "                                               house_loc_left:house_loc_right]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* other rasters are unprocessed and low resolution for visual check only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_row, max_row=int(round(upper_crop*height)), int(round(lower_crop*height))\n",
    "min_col, max_col=int(round(house_loc_left/downscale_factor)), int(round(house_loc_right/downscale_factor))\n",
    "\n",
    "rgb_arr_clipped=rgb[min_row:max_row, min_col:max_col,:]\n",
    "class_arr_clipped=classification[min_row:max_row, min_col:max_col]\n",
    "depth_arr_clipped=depth[min_row:max_row, min_col:max_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_rgb=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_rgb.tif'))\n",
    "out_path_elevation=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_elevation_resampled.tif'))\n",
    "out_path_intensity=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_intensity_resampled.tif'))\n",
    "out_path_classification=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_classification.tif'))\n",
    "out_path_depth=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_depth.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsave(out_path_rgb, rgb_arr_clipped)\n",
    "imsave(out_path_classification, class_arr_clipped)\n",
    "imsave(out_path_depth, depth_arr_clipped)\n",
    "imsave(out_path_elevation, z_processed)\n",
    "imsave(out_path_intensity, intensity_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch apply to all buildings with nearby panoramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gdf_building_points)):\n",
    "    building_ufi=gdf_building_points.iloc[i]['UFI']\n",
    "    house_loc_left, house_loc_right = int(gdf_building_points.iloc[i]['house_loc_left']), int(gdf_building_points.iloc[i]['house_loc_right'])\n",
    "    try:\n",
    "        # find las by UFI\n",
    "        las_file_path=glob.glob(las_files_folder+'*'+'_UFI_'+str(building_ufi)+'.las')[0]\n",
    "        \n",
    "        out_path_rgb=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_rgb.tif'))\n",
    "        out_path_elevation=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_elevation_resampled.tif'))\n",
    "        out_path_intensity=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_intensity_resampled.tif'))\n",
    "        out_path_classification=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_classification.tif'))\n",
    "        out_path_depth=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_depth.tif'))\n",
    "\n",
    "        if os.path.exists(out_path_rgb) and os.path.exists(out_path_elevation) and os.path.exists(out_path_depth)\\\n",
    "            and os.path.exists(out_path_intensity) and os.path.exists(out_path_classification):\n",
    "            print('rasters exist, skipping...')\n",
    "        else:\n",
    "            # get viewpoint metadata\n",
    "            lat, lon, elev = [gdf_building_points.iloc[i]['LATITUDE'],gdf_building_points.iloc[i]['LONGITUDE'],gdf_building_points.iloc[i]['LTP_z_m']] # lidar data is in AHD\n",
    "            x_proj, y_proj = transformer.transform(lon, lat)  # lon, lat order\n",
    "            camera_pos_proj = [x_proj, y_proj, elev]\n",
    "            camera_angles=[gdf_building_points.iloc[i]['Heading_deg'], gdf_building_points.iloc[i]['Pitch_deg'], (-1)*gdf_building_points.iloc[i]['Roll_deg']]\n",
    "            \n",
    "            # project as rasters\n",
    "            rgb, z, depth, classification, intensity = project_las_to_equirectangular(input_las=las_file_path, camera_pos=camera_pos_proj,\n",
    "                                                                        camera_angles=camera_angles, width=width, height=height)\n",
    "            \n",
    "            # fill small holes\n",
    "            z_arr_filled = fill_small_nans(z, max_hole_size=10, nodata_value=9999)\n",
    "            intensity_filled = fill_small_nans(intensity, max_hole_size=10, nodata_value=255)\n",
    "\n",
    "            # upsample\n",
    "            z_filled_resampled=resize_preserve_nans(z_arr_filled,height_panorama, width_panorama, nodata_value=9999)\n",
    "            intensity_filled_resampled=resize_preserve_nans(intensity_filled, height_panorama, width_panorama, nodata_value=255)\n",
    "\n",
    "            # crop\n",
    "            z_processed=z_filled_resampled[int(round(upper_crop*height_panorama)):int(round(lower_crop*height_panorama)),\n",
    "                                           house_loc_left:house_loc_right]\n",
    "            intensity_processed=intensity_filled_resampled[int(round(upper_crop*height_panorama)):int(round(lower_crop*height_panorama)),\n",
    "                                                           house_loc_left:house_loc_right]\n",
    "            \n",
    "            min_row, max_row=int(round(upper_crop*height)), int(round(lower_crop*height))\n",
    "            min_col, max_col=int(round(house_loc_left/downscale_factor)), int(round(house_loc_right/downscale_factor))\n",
    "            rgb_arr_clipped=rgb[min_row:max_row, min_col:max_col,:]\n",
    "            class_arr_clipped=classification[min_row:max_row, min_col:max_col]\n",
    "            depth_arr_clipped=depth[min_row:max_row, min_col:max_col]\n",
    "\n",
    "            #save\n",
    "            imsave(out_path_rgb, rgb_arr_clipped)\n",
    "            imsave(out_path_classification, class_arr_clipped)\n",
    "            imsave(out_path_depth, depth_arr_clipped)\n",
    "            imsave(out_path_elevation, z_processed)\n",
    "            imsave(out_path_intensity, intensity_processed)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
