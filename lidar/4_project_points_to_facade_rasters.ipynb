{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates projection of point cloud at the viewpoint of nearby panorma as rasters, and export clipped rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "# from pyproj import Transformer\n",
    "# from scipy.spatial.transform import Rotation as R\n",
    "# from lidar.point_cloud_processings import remove_noise, get_rotation_matrix, project_lidar_perspective, project_lidar_equirectangular\n",
    "import geopandas as gpd\n",
    "import pdal\n",
    "import glob\n",
    "import pyproj\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import map_coordinates, generic_filter\n",
    "from skimage.io import imsave\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_points_file=r'/home/ubuntu/lavender_floor_height/output/Final_Wagga_training_samples_pano_metadata_clipping.geojson'\n",
    "las_files_folder = r\"/mnt/floorheightvolume/lidar_Wagga/clipped/\"\n",
    "out_folder=r\"/mnt/floorheightvolume/lidar_Wagga/clipped_projected/\"\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load building points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_building_points=gpd.read_file(building_points_file)\n",
    "gdf_building_points=gdf_building_points[gdf_building_points[\"USAGE\"]==\"Residential\"].reset_index(drop=True)\n",
    "gdf_building_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test workflow with one building example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify corresponding las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building_ufi=1271\n",
    "# gdf_building_points[gdf_building_points['UFI']==building_ufi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=90\n",
    "building_ufi=gdf_building_points.iloc[i]['UFI']\n",
    "house_loc_left, house_loc_right = int(gdf_building_points.iloc[i]['house_loc_left']), int(gdf_building_points.iloc[i]['house_loc_right'])\n",
    "las_file_path=glob.glob(las_files_folder+'*'+'_UFI_'+str(building_ufi)+'.las')[0]\n",
    "las_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_las_to_equirectangular( input_las, camera_pos=[0, 0, 0], camera_angles=[0, 0, 0], \n",
    "                                   width=2048, height=1024, nodata_float=9999, nodata_int=255):\n",
    "    \"\"\"\n",
    "    Projects LAS to equirectangular maps with intrinsic XYZ rotation.\n",
    "    Returns:\n",
    "        rgb_raster (np.uint8): (H,W,3) RGB image\n",
    "        z_raster (np.float32): (H,W) elevation map\n",
    "        depth_raster (np.float32): (H,W) depth map\n",
    "        class_raster (np.float32): (H,W) classification map\n",
    "    \"\"\"\n",
    "    # --- Data Loading ---\n",
    "    pipeline = pdal.Reader.las(filename=input_las).pipeline()\n",
    "    pipeline.execute()\n",
    "    points = pipeline.arrays[0]\n",
    "    x, y, z = points[\"X\"], points[\"Y\"], points[\"Z\"]\n",
    "    rgb = np.vstack([points[\"Red\"], points[\"Green\"], points[\"Blue\"]]).T/256 # 16 bits\n",
    "    classification = points[\"Classification\"].astype(np.uint8)\n",
    "    intensity = points[\"Intensity\"].astype(np.uint8)\n",
    "    print(\"RGB min/max:\", rgb.min(axis=0), rgb.max(axis=0))\n",
    "\n",
    "    # --- Coordinate Transformation ---\n",
    "    # Convert angles to radians\n",
    "    yaw_rad = np.radians(camera_angles[0])\n",
    "    pitch_rad = np.radians(camera_angles[1])\n",
    "    roll_rad = np.radians(camera_angles[2])\n",
    "\n",
    "    # Translate to camera origin\n",
    "    x -= camera_pos[0]\n",
    "    y -= camera_pos[1]\n",
    "    z -= camera_pos[2]\n",
    "\n",
    "    # Intrinsic XYZ rotation matrices\n",
    "    R_roll = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(roll_rad), -np.sin(roll_rad)],\n",
    "        [0, np.sin(roll_rad), np.cos(roll_rad)]\n",
    "    ])\n",
    "    R_pitch = np.array([\n",
    "        [np.cos(pitch_rad), 0, np.sin(pitch_rad)],\n",
    "        [0, 1, 0],\n",
    "        [-np.sin(pitch_rad), 0, np.cos(pitch_rad)]\n",
    "    ])\n",
    "    R_heading = np.array([\n",
    "        [np.cos(yaw_rad), -np.sin(yaw_rad), 0],\n",
    "        [np.sin(yaw_rad), np.cos(yaw_rad), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    R_total = R_heading @ R_pitch @ R_roll  # Intrinsic XYZ order\n",
    "\n",
    "    # Apply rotation\n",
    "    coords = np.vstack([x, y, z])\n",
    "    coords_local = R_total @ coords\n",
    "\n",
    "    # Transform to camera coordinate convention:\n",
    "    #    LiDAR's +Z (up) should become camera's +Y (down)\n",
    "    #    LiDAR's +Y (north) should become camera's -Z (forward)\n",
    "    x_cam = coords_local[0]\n",
    "    y_cam = -coords_local[2]  # LiDAR Z (up) -> Camera Y (down)\n",
    "    z_cam = coords_local[1]   # LiDAR Y (north) -> Camera Z (forward)\n",
    "    print(\"Camera-relative Z:\", z_cam.min(), z_cam.max())\n",
    "\n",
    "    # --- Equirectangular Projection ---\n",
    "    r = np.sqrt(x_cam**2 + y_cam**2 + z_cam**2)  # Depth\n",
    "    theta = np.arctan2(x_cam, z_cam)             # Azimuth\n",
    "    phi = np.arccos(-y_cam / r)                  # flip Zenith\n",
    "    \n",
    "    # Normalized coordinates [0,1] range\n",
    "    u_norm = 0.5 * (theta/np.pi + 1)\n",
    "    v_norm = phi/np.pi\n",
    "\n",
    "    # Convert to pixel coordinates using precise scaling\n",
    "    u_idx = np.floor(u_norm * (width - 1)).astype(np.int32)\n",
    "    v_idx = np.floor(v_norm * (height - 1)).astype(np.int32)\n",
    "\n",
    "    # Ensure indices are within bounds\n",
    "    u_idx = np.clip(u_idx, 0, width - 1)\n",
    "    v_idx = np.clip(v_idx, 0, height - 1)\n",
    "\n",
    "    # --- Rasterization ---\n",
    "    rgb_raster = np.full((height, width, 3), nodata_int, dtype=np.uint8)\n",
    "    z_raster = np.full((height, width), nodata_float, dtype=np.float32)\n",
    "    depth_raster = np.full((height, width), nodata_float, dtype=np.float32)\n",
    "    class_raster = np.full((height, width), nodata_int, dtype=np.uint8)\n",
    "    intensity_raster = np.full((height, width), nodata_int, dtype=np.uint8)\n",
    "\n",
    "    # Sort points by depth (closest first)\n",
    "    sort_idx = np.argsort(r)\n",
    "    u_idx = u_idx[sort_idx]\n",
    "    v_idx = v_idx[sort_idx]\n",
    "    r = r[sort_idx]\n",
    "    rgb = rgb[sort_idx]\n",
    "    z = z[sort_idx]\n",
    "    classification = classification[sort_idx]\n",
    "    intensity = intensity[sort_idx]\n",
    "\n",
    "    # Vectorized depth test\n",
    "    valid = (u_idx >= 0) & (u_idx < width) & (v_idx >= 0) & (v_idx < height)\n",
    "    u_valid = u_idx[valid]\n",
    "    v_valid = v_idx[valid]\n",
    "\n",
    "    # Update only if closer than existing depth\n",
    "    mask = r[valid] < depth_raster[v_valid, u_valid]\n",
    "    depth_raster[v_valid[mask], u_valid[mask]] = r[valid][mask]\n",
    "    rgb_raster[v_valid[mask], u_valid[mask]] = (rgb[valid][mask]).astype(np.uint8)\n",
    "    z_raster[v_valid[mask], u_valid[mask]] = z[valid][mask] + camera_pos[2]\n",
    "    class_raster[v_valid[mask], u_valid[mask]] = classification[valid][mask]\n",
    "    intensity_raster[v_valid[mask], u_valid[mask]] = intensity[valid][mask]\n",
    "\n",
    "    # # for debugging purpose\n",
    "    # print('number of valid depth points: ',np.sum(depth_raster != nodata_float))\n",
    "    # print('number of valid elevation points: ',np.sum(z_raster!=nodata_float))\n",
    "    # print('number of classification points: ',np.sum(class_raster != nodata_int))\n",
    "    # print('number of valid rgb points: ',np.sum(np.any(rgb_raster!= nodata_int, axis=-1)))\n",
    "    # print('number of valid intensity points: ',np.sum(intensity_raster != nodata_int))\n",
    "    \n",
    "    return rgb_raster, z_raster, depth_raster, class_raster, intensity_raster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject trajectory coordinates to match lidar points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = pyproj.Transformer.from_crs(\"EPSG:7844\",  # GDA2020 geographic (lat/lon)\n",
    "                                          \"EPSG:7855\",      # MGA Zone 55 (EPSG:7855)\n",
    "                                          always_xy=True)\n",
    "lat, lon, elev = [gdf_building_points.iloc[i]['LATITUDE'],gdf_building_points.iloc[i]['LONGITUDE'],gdf_building_points.iloc[i]['LTP_z_m']] # lidar data is in AHD\n",
    "x_proj, y_proj = transformer.transform(lon, lat)  # lon, lat order\n",
    "camera_pos_proj = [x_proj, y_proj, elev]\n",
    "camera_angles=[gdf_building_points.iloc[i]['Heading_deg'], gdf_building_points.iloc[i]['Pitch_deg'], gdf_building_points.iloc[i]['Roll_deg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densify points (optional depending on performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_densified_path=las_file_path.split('.')[0]+'_densified.las'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_json = {\n",
    "#     \"pipeline\": [\n",
    "#         las_file_path,\n",
    "#         {\n",
    "#             \"type\": \"filters.poisson\",\n",
    "#             \"depth\": 10, # Start with a mid-range depth (this controls resolution)\n",
    "#         },\n",
    "#         out_densified_path\n",
    "#     ]\n",
    "# }\n",
    "# pipeline = pdal.Pipeline(json.dumps(pipeline_json))\n",
    "# pipeline.execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project the point cloud as rasters\n",
    "* Note: using the same width/height ratio as panoramas\n",
    "* reduced resolution to improve sampling of surface points compared to background points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_crop=0.25\n",
    "lower_crop=0.6 # consistent with panorama clipping\n",
    "width_panorama=11000\n",
    "height_panorama=5500  # panoramas parameters\n",
    "downscale_factor=4 # scale factor between panorama and projected lidar rasters\n",
    "width=int(width_panorama/downscale_factor)\n",
    "height=int(height_panorama/downscale_factor)\n",
    "rgb, z, depth, classification, intensity = project_las_to_equirectangular(input_las=las_file_path, camera_pos=camera_pos_proj,\n",
    "                                                               camera_angles=camera_angles, width=width, height=height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample to the same resolution as panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_preserve_nans(arr, target_height, target_width, nodata_value=9999):\n",
    "    \"\"\"\n",
    "    Resizes an array while preserving NoData regions, preventing artifacts at edges.\n",
    "    \"\"\"\n",
    "    # Create valid mask (1=valid, 0=nodata)\n",
    "    valid_mask = (arr != nodata_value)\n",
    "    \n",
    "    # For interpolation, replace nodata with 0 but we'll mask later\n",
    "    # arr_filled = np.where(valid_mask, arr, 0)\n",
    "    \n",
    "    # Compute scale factors\n",
    "    scale_y = arr.shape[0] / target_height\n",
    "    scale_x = arr.shape[1] / target_width\n",
    "\n",
    "    # Create coordinate grids for interpolation\n",
    "    y_idx, x_idx = np.meshgrid(np.linspace(0.5, arr.shape[0]-0.5, target_height),\n",
    "                               np.linspace(0.5, arr.shape[1]-0.5, target_width),\n",
    "                               indexing='ij')\n",
    "    coords = np.array([y_idx.ravel(), x_idx.ravel()])\n",
    "\n",
    "    # Resize mask using nearest-neighbor to keep sharp edges\n",
    "    resized_mask = resize(valid_mask.astype(float),\n",
    "                         (target_height, target_width),\n",
    "                         order=0,  # Nearest-neighbor\n",
    "                         anti_aliasing=False) > 0.5\n",
    "\n",
    "    # Create distance-to-edge map to identify border regions\n",
    "    from scipy.ndimage import distance_transform_edt\n",
    "    dist_to_nodata = distance_transform_edt(valid_mask)\n",
    "    edge_zone = dist_to_nodata <= 1  # Pixels adjacent to nodata\n",
    "\n",
    "    # Interpolate main data\n",
    "    # resized_data = map_coordinates(arr_filled, coords, order=1, cval=0)\n",
    "    resized_data = map_coordinates(arr, coords, order=1, cval=nodata_value)\n",
    "    resized_data = resized_data.reshape((target_height, target_width))\n",
    "\n",
    "    # For edge pixels, use nearest-neighbor to prevent bleeding\n",
    "    if np.any(edge_zone):\n",
    "        # edge_data = map_coordinates(arr_filled, coords, order=0, cval=0)\n",
    "        edge_data = map_coordinates(arr, coords, order=0, cval=nodata_value)\n",
    "        edge_data = edge_data.reshape((target_height, target_width))\n",
    "        \n",
    "        # Find where original edge pixels map to in output\n",
    "        edge_coverage = map_coordinates(edge_zone.astype(float), coords, order=1)\n",
    "        edge_coverage = edge_coverage.reshape((target_height, target_width)) > 0.1\n",
    "        \n",
    "        # Use nearest-neighbor result for edge-affected areas\n",
    "        resized_data = np.where(edge_coverage, edge_data, resized_data)\n",
    "\n",
    "    # Restore NoData values using the resized mask\n",
    "    resized_data[~resized_mask] = nodata_value\n",
    "    \n",
    "    return resized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resize while preserving remaining NaNs\n",
    "# new_width = z_arr_clipped_filled.shape[0]*downscale_factor\n",
    "# new_height = z_arr_clipped_filled.shape[1]*downscale_factor\n",
    "# z_arr_filled_resampled=resize_preserve_nans(z_arr_clipped_filled,new_width,new_height)\n",
    "\n",
    "z_arr_resampled=resize_preserve_nans(z,width_panorama,height_panorama,nodata_value=9999)\n",
    "intensity_resampled=resize_preserve_nans(intensity,width_panorama,height_panorama, nodata_value=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate gaps on elevation and intensity rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_small_nans(arr, max_hole_size=10, nodata_value=9999):\n",
    "    \"\"\"\n",
    "    Fills small nodata regions using local interpolation from surrounding valid pixels.\n",
    "    \n",
    "    Parameters:\n",
    "        arr: 2D numpy array with nodata values\n",
    "        max_hole_size: Maximum size (in pixels) of nodata regions to fill\n",
    "        nodata_value: The value representing nodata (default: 9999)\n",
    "        \n",
    "    Returns:\n",
    "        Array with small nodata regions filled, large ones preserved\n",
    "    \"\"\"\n",
    "    print(f\"Initial nodata count: {np.sum(arr == nodata_value)}\")\n",
    "    \n",
    "    # Create mask of nodata regions\n",
    "    nodata_mask = (arr == nodata_value)\n",
    "    \n",
    "    # Label connected nodata regions\n",
    "    labeled, num_features = ndimage.label(nodata_mask)\n",
    "    \n",
    "    # Measure size of each nodata region\n",
    "    sizes = ndimage.sum(nodata_mask, labeled, range(num_features + 1))\n",
    "    \n",
    "    # Create output array\n",
    "    filled = arr.copy()\n",
    "    \n",
    "    # Compute global distance transform once (from all valid pixels)\n",
    "    distances, indices = ndimage.distance_transform_edt(\n",
    "        nodata_mask,  # Important: input is the nodata mask\n",
    "        return_indices=True\n",
    "    )\n",
    "    \n",
    "    # Process each nodata region\n",
    "    for i in range(1, num_features + 1):\n",
    "        region_mask = (labeled == i)\n",
    "        region_size = np.sum(region_mask)\n",
    "        \n",
    "        if region_size <= max_hole_size:\n",
    "            # Fill using precomputed nearest valid pixels\n",
    "            filled[region_mask] = arr[\n",
    "                indices[0][region_mask], \n",
    "                indices[1][region_mask]\n",
    "            ]\n",
    "    print(f\"Final nodata count: {np.sum(filled == nodata_value)}\")\n",
    "    return filled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill small holes\n",
    "# z_arr_clipped_filled = fill_small_nans(z_arr_clipped, max_hole_size=5)\n",
    "z_arr_resampled_filled = fill_small_nans(z_arr_resampled, max_hole_size=5)\n",
    "intensity_resampled_filled = fill_small_nans(intensity_resampled, max_hole_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip projected rasters to the same region as panoramas\n",
    "* only elevation and intensity rasters were upsampled for use in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_resampled_clipped=z_arr_resampled_filled[house_loc_left:house_loc_right, \n",
    "                                           np.round(upper_crop*height_panorama):np.round(lower_crop*height_panorama)]\n",
    "intensity_resampled_clipped=intensity_resampled_filled[house_loc_left:house_loc_right, \n",
    "                                                       np.round(upper_crop*height_panorama):np.round(lower_crop*height_panorama)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* other rasters are unprocessed and low resolution for visual check only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_row, max_row=np.round(house_loc_left/downscale_factor), np.round(house_loc_right/downscale_factor)\n",
    "min_col, max_col=np.round(upper_crop*height), np.round(lower_crop*height)\n",
    "\n",
    "rgb_arr_clipped=rgb[min_row:max_row, min_col:max_col,:]\n",
    "class_arr_clipped=classification[min_row:max_row, min_col:max_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_rgb=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_rgb.tif'))\n",
    "out_path_elevation=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_elevation_resampled.tif'))\n",
    "out_path_intensity=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_intensity_resampled.tif'))\n",
    "out_path_classification=os.path.join(out_folder,os.path.basename(las_file_path).replace('.las','_classification.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsave(out_path_rgb, rgb_arr_clipped)\n",
    "imsave(out_path_classification, class_arr_clipped)\n",
    "imsave(out_path_elevation, z_resampled_clipped)\n",
    "imsave(out_path_intensity, intensity_resampled_clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch apply to all buildings with nearby panoramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
