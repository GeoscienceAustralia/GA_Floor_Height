{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder='data'\n",
    "out_folder='output\\Wagga'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load points data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_points=os.path.join(input_folder,\"Final_Wagga.shp\")\n",
    "gdf_points=gpd.read_file(add_points).to_crs('epsg:4326')\n",
    "gdf_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify ground-surveyed group\n",
    "- using standard step distance of 0.28 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_m=0.28\n",
    "tolerance = 1e-12  # A small tolerance to handle floating-point precision\n",
    "gdf_points['Floor_height']=gdf_points['Floor_Leve']-gdf_points['Ground_Lev']\n",
    "gdf_points['Floor_height'] = gdf_points['Floor_height'].round(4) # Limit 'Floor_height'decimal places\n",
    "gdf_points['Ground_surveyed']=1\n",
    "gdf_points.loc[np.abs(gdf_points['Floor_height'] % step_m) < tolerance,'Ground_surveyed']=0\n",
    "gdf_points.explore(column='Ground_surveyed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatially cluster the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters\n",
    "n_clusters = 5\n",
    "\n",
    "# Convert geometries to numpy array of coordinates\n",
    "coords = np.array(list(gdf_points.geometry.apply(lambda point: (point.x, point.y))))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "gdf_points['cluster'] = kmeans.fit_predict(coords)\n",
    "\n",
    "gdf_points.explore(column='cluster')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin continous attributes\n",
    "- Ground elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 3  # Number of bins\n",
    "gdf_points['Ground_Level_bin'] = pd.qcut(gdf_points['Ground_Lev'], q=n_bins, labels=['Low','Medium','High'], duplicates='drop')\n",
    "print(gdf_points['Ground_Level_bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_height = gdf_points['Floor_height'].min()\n",
    "# max_height = gdf_points['Floor_height'].max()\n",
    "# bins = np.linspace(min_height, max_height, n_bins + 1)\n",
    "# # Create quantile-based bins for 'Floor_height'\n",
    "# gdf_points['Floor_height_bin'] = pd.cut(gdf_points['Floor_height'], bins=n_bins, labels=['Low','Medium','High'])\n",
    "\n",
    "# # Check the distribution of the bins\n",
    "# print(gdf_points['Floor_height_bin'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform stratified sampling using\n",
    "- Spatial clustering\n",
    "- Either or not ground-surveyed\n",
    "- Age (before or after 1960)\n",
    "- Wall material\n",
    "- Usage\n",
    "- Bined ground elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac=0.25\n",
    "sampled_dfs = []\n",
    "columns = ['cluster','Ground_surveyed', 'AGE','WALL_M','USAGE','Ground_Level_bin']\n",
    "# Group by both clusters and the binned columns\n",
    "for (cluster_label, attr1, attr2, attr3, attr4, attr5), group in gdf_points.groupby(columns):\n",
    "    if len(group) > 1:\n",
    "        sampled_group = group.sample(frac=frac, random_state=42)\n",
    "        sampled_dfs.append(sampled_group)\n",
    "\n",
    "# Concatenate the sampled groups into a single GeoDataFrame\n",
    "sampled_gdf = gpd.GeoDataFrame(pd.concat(sampled_dfs))\n",
    "sampled_gdf.explore(column='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampled_gdf[['Ground_Level_bin', 'WALL_M']].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export sampled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file=os.path.join(out_folder,\"Final_Wagga_training_samples.geojson\")\n",
    "sampled_gdf.to_file(output_file, driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floorheight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
